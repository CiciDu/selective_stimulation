{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install botorch\n",
    "!pip install brian2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Jupyter setup ---\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# --- System path setup ---\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.getcwd())\n",
    "\n",
    "# Verify the current directory\n",
    "print(\"Current directory:\", os.getcwd())\n",
    "\n",
    "# --- Environment settings ---\n",
    "nrn_options = \"-nogui -NSTACK 100000 -NFRAME 20000\"\n",
    "os.environ[\"NEURON_MODULE_OPTIONS\"] = nrn_options\n",
    "\n",
    "# --- Core Python libraries ---\n",
    "import math\n",
    "import time\n",
    "import warnings\n",
    "from dataclasses import dataclass\n",
    "from functools import partial\n",
    "\n",
    "# --- NumPy & Matplotlib ---\n",
    "import numpy as np\n",
    "np.random.seed(237)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "# --- Skopt (Bayesian optimization) ---\n",
    "from skopt import gp_minimize\n",
    "from skopt.space import Real\n",
    "from skopt.plots import plot_gaussian_process, plot_convergence\n",
    "\n",
    "# --- PyTorch & GPyTorch ---\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.quasirandom import SobolEngine\n",
    "\n",
    "import gpytorch\n",
    "from gpytorch.constraints import Interval\n",
    "from gpytorch.kernels import MaternKernel, RBFKernel, ScaleKernel\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "\n",
    "# --- BoTorch ---\n",
    "from botorch import manual_seed\n",
    "from botorch.acquisition import LogExpectedImprovement, qExpectedImprovement, qLogExpectedImprovement\n",
    "from botorch.exceptions import BadInitialCandidatesWarning\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.generation import MaxPosteriorSampling\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.models.gp_regression import SingleTaskGP as STGP\n",
    "from botorch.models.kernels import InfiniteWidthBNNKernel\n",
    "from botorch.models.transforms.outcome import Standardize\n",
    "from botorch.optim import optimize_acqf\n",
    "from botorch.optim.optimize import optimize_acqf as optimize_acqf_fn\n",
    "from botorch.test_functions import Ackley\n",
    "from botorch.utils.sampling import draw_sobol_samples\n",
    "from botorch.utils.transforms import unnormalize\n",
    "\n",
    "# --- Brian2 ---\n",
    "from brian2 import *\n",
    "\n",
    "# --- Custom Utilities ---\n",
    "from utils.brian2_utils import set_params_utils, eqs_utils, plotting_utils, obj_func_utils\n",
    "from utils.bo_utils import ibnn_utils, shared_utils, turbo_utils, baseline_bo_utils\n",
    "\n",
    "# --- Warning filters ---\n",
    "warnings.filterwarnings(\"ignore\", category=BadInitialCandidatesWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# populations\n",
    "N = 700\n",
    "N_E = int(N * 0.8)  # pyramidal neurons\n",
    "N_I = int(N * 0.2)  # interneurons\n",
    "f = 0.1\n",
    "p = 3\n",
    "C_ext = 800\n",
    "DC_amp = 0\n",
    "\n",
    "# external stimuli\n",
    "# rate = 3 * Hz # in external noise\n",
    "currents_to_track = ['I_syn', 'I_AMPA_ext', 'I_GABA_rec', 'I_AMPA_rec', 'I_NMDA_rec', 'I_DC1', 'I_DC2']\n",
    "currents_to_plot = currents_to_track"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## currents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DC_input_ts = 1 * ms\n",
    "sino_input_ts = 0.1 * ms\n",
    "\n",
    "# currently set the duration of all currents to 0, so that they are not applied\n",
    "\n",
    "DC_start_time1 = 0  # in ms\n",
    "# DC_duration1 = 1000  # in ms\n",
    "DC_duration1 = 0  # in ms\n",
    "DC_amp1 = 0.1  # in nA\n",
    "DC_amp_slope1 = 0.001  # in nA/ms\n",
    "\n",
    "DC_start_time2 = 500  # in ms\n",
    "# DC_duration2 = 2000  # in ms\n",
    "DC_duration2 = 0  # in ms\n",
    "DC_amp2 = -0.05  # in nA\n",
    "DC_amp_slope2 = -0.001  # in nA/ms\n",
    "\n",
    "sino_start_time1 = 0  # in ms\n",
    "# sino_duration1=3000  # in ms\n",
    "sino_duration1=0  # in ms\n",
    "sino_amp1=0.5  # in nA\n",
    "sino_freq1=30  # in Hz\n",
    "\n",
    "sino_start_time2 = 1000  # in ms\n",
    "# sino_duration2=2000  # in ms\n",
    "sino_duration2=0  # in ms\n",
    "sino_amp2=0.2  # in nA\n",
    "sino_freq2=50  # in Hz\n",
    "\n",
    "\n",
    "\n",
    "DC_input1 = set_params_utils.set_DC_input(DC_amp=DC_amp1, # in nA\n",
    "                DC_amp_slope=DC_amp_slope1, # in nA/ms\n",
    "                DC_duration=DC_duration1, # in ms\n",
    "                DC_start_time=DC_start_time1, # in ms\n",
    "                timestep=DC_input_ts\n",
    "                )\n",
    "\n",
    "DC_input2 = set_params_utils.set_DC_input(DC_amp=DC_amp2, # in nA\n",
    "                DC_amp_slope=DC_amp_slope2, # in nA/ms\n",
    "                DC_duration=DC_duration2, # in ms\n",
    "                DC_start_time=DC_start_time2, # in ms\n",
    "                timestep=DC_input_ts\n",
    "                )\n",
    "\n",
    "sino_input1 = set_params_utils.set_sino_input(sino_start_time=sino_start_time1, # in ms\n",
    "                    sino_duration=sino_duration1, # in ms\n",
    "                    sino_amp=sino_amp1, # in nA\n",
    "                    sino_freq=sino_freq1, # in Hz\n",
    "                    timestep=sino_input_ts\n",
    "                    )\n",
    "\n",
    "sino_input2 = set_params_utils.set_sino_input(sino_start_time=sino_start_time2, # in ms\n",
    "                    sino_duration=sino_duration2, # in ms\n",
    "                    sino_amp=sino_amp2, # in nA\n",
    "                    sino_freq=sino_freq2, # in Hz\n",
    "                    timestep=sino_input_ts\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run initial simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_scope()\n",
    "\n",
    "N_sub = int(N_E * f)\n",
    "N_non = int(N_E * (1. - f * p))\n",
    "\n",
    "\n",
    "E_neuron_index = [0] # index of the neuron in the population\n",
    "E_index_map = {0: 'nonselective'} # map the index in the monitor to population name\n",
    "for i in range(p):\n",
    "    E_neuron_index.append(N_non + i * N_sub)\n",
    "    E_index_map[i+1] = f'selective {i}'\n",
    "\n",
    "\n",
    "# voltage\n",
    "V_L, V_thr, V_reset, V_E, V_I = set_params_utils.set_voltage()\n",
    "# membrane capacitance and membrane leak\n",
    "C_m_E, C_m_I, g_m_E, g_m_I = set_params_utils.set_membrane_params()\n",
    "\n",
    "# AMPA (excitatory)\n",
    "g_AMPA_ext_E, g_AMPA_rec_E, g_AMPA_ext_I, g_AMPA_rec_I, tau_AMPA = set_params_utils.set_AMPA_params(N_E)\n",
    "# NMDA (excitatory)\n",
    "g_NMDA_E, g_NMDA_I, tau_NMDA_rise, tau_NMDA_decay, alpha, Mg2 = set_params_utils.set_NMDA_params(N_E)\n",
    "# GABAergic (inhibitory)\n",
    "g_GABA_E, g_GABA_I, tau_GABA = set_params_utils.set_GABA_params(N_I)\n",
    "\n",
    "# Write the equations for the target population (e.g., excitatory population P_E)\n",
    "eqs_E = eqs_utils.write_eqs_E()\n",
    "eqs_I = eqs_utils.write_eqs_I()\n",
    "eqs_glut, eqs_pre_glut, eqs_pre_gaba = eqs_utils.write_other_eqs()\n",
    "\n",
    "# neuron groups \n",
    "P_E, P_I = set_params_utils.set_neuron_groups(N_E, N_I, eqs_E, eqs_I, V_L)\n",
    "# synapses\n",
    "external_noise_rate = 3 * Hz\n",
    "C_E, C_I, C_E_E, C_E_I, C_I_I, C_I_E, C_P_E, C_P_I = set_params_utils.set_synapses(P_E, P_I, N_E, N_I, N_sub, N_non, p, f, C_ext, external_noise_rate, eqs_glut, eqs_pre_glut, eqs_pre_gaba)\n",
    "\n",
    "\n",
    "N_activity_plot = 15\n",
    "current_monitor_E, r_E_sels, r_E, r_I = set_params_utils.set_monitors_for_optimization_algorithm(N_activity_plot, N_non, N_sub, p, P_E, P_I, E_neuron_index=E_neuron_index, currents_to_track=currents_to_track)\n",
    "\n",
    "## set external stimuli\n",
    "# at 1s, select population 1\n",
    "C_selection = int(f * C_ext)\n",
    "rate_selection = 25 * Hz\n",
    "\n",
    "\n",
    "stimuli1 = TimedArray(np.r_[np.zeros(40), np.ones(2), np.zeros(100)], dt=25 * ms)\n",
    "input1 = PoissonInput(P_E[N_non:N_non + N_sub], 's_AMPA_ext', C_selection, rate_selection, 'stimuli1(t)')\n",
    "\n",
    "# # at 2s, select population 2\n",
    "# stimuli2 = TimedArray(np.r_[np.zeros(80), np.ones(2), np.zeros(100)], dt=25 * ms)\n",
    "# input2 = PoissonInput(P_E[N_non + N_sub:N_non + 2 * N_sub], 's_AMPA_ext', C_selection, rate_selection, 'stimuli2(t)')\n",
    "\n",
    "\n",
    "# simulate, can be long >120s\n",
    "net = Network(collect())\n",
    "net.add(r_E_sels)\n",
    "net.add(P_E, P_I, C_E_E, C_E_I, C_I_I, C_I_E, C_P_E, C_P_I)\n",
    "\n",
    "\n",
    "net.store('initial')\n",
    "\n",
    "net.run(5 * second, report='stdout')\n",
    "\n",
    "plotting_utils.plot_firing_rate(r_E, r_I, r_E_sels)\n",
    "plotting_utils.plot_currents(current_monitor_E, None, currents_to_plot, E_index_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## set obj func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DC_amp1_range = [-0.3, 0]\n",
    "DC_amp_slope1_range = [-0.2, 0.2]\n",
    "DC_start_time1_range = [0, 4000]\n",
    "DC_duration1_range = [20, 5000]\n",
    "\n",
    "\n",
    "DC_amp2_range = [0, 0.3]\n",
    "DC_amp_slope2_range = [-0.2, 0.2]\n",
    "DC_start_time2_range = [0, 4000]\n",
    "DC_duration2_range = [20, 4000]\n",
    "# sino_start_time1_range = [0, 4000]\n",
    "# sino_duration1_range = [20, 4000]\n",
    "# sino_amp1_range = [0, 0.3]\n",
    "# sino_freq1_range = [0.01, 10]\n",
    "\n",
    "# sino_start_time2_range = [0, 4000]\n",
    "# sino_duration2_range = [20, 4000]\n",
    "# sino_amp2_range = [0, 0.3]\n",
    "# sino_freq2_range = [0.01, 10]\n",
    "\n",
    "\n",
    "space = [\n",
    "            Real(DC_start_time1_range[0], DC_start_time1_range[1], name='DC_start_time1'),\n",
    "            Real(DC_duration1_range[0], DC_duration1_range[1], name='DC_duration1'),\n",
    "            Real(DC_amp1_range[0], DC_amp1_range[1], name='DC_amp1'),\n",
    "            Real(DC_amp_slope1_range[0], DC_amp_slope1_range[1], name='DC_amp_slope1'),\n",
    "            Real(DC_start_time2_range[0], DC_start_time2_range[1], name='DC_start_time2'),\n",
    "            Real(DC_duration2_range[0], DC_duration2_range[1], name='DC_duration2'),\n",
    "            Real(DC_amp2_range[0], DC_amp2_range[1], name='DC_amp2'),\n",
    "            Real(DC_amp_slope2_range[0], DC_amp_slope2_range[1], name='DC_amp_slope2'),\n",
    "            # Real(sino_start_time1_range[0], sino_start_time1_range[1], name='sino_start_time1'),\n",
    "            # Real(sino_duration1_range[0], sino_duration1_range[1], name='sino_duration1'),\n",
    "            # Real(sino_amp1_range[0], sino_amp1_range[1], name='sino_amp1'),\n",
    "            # Real(sino_freq1_range[0], sino_freq1_range[1], name='sino_freq1'),\n",
    "            # Real(sino_start_time2_range[0], sino_start_time2_range[1], name='sino_start_time2'),\n",
    "            # Real(sino_duration2_range[0], sino_duration2_range[1], name='sino_duration2'),\n",
    "            # Real(sino_amp2_range[0], sino_amp2_range[1], name='sino_amp2'),\n",
    "            # Real(sino_freq2_range[0], sino_freq2_range[1], name='sino_freq2')\n",
    "            ]\n",
    "\n",
    "\n",
    "namespace = {'V_L': V_L, 'V_thr': V_thr, 'V_reset': V_reset, 'V_E': V_E, 'V_I': V_I,\n",
    "            'C_m_E': C_m_E, 'C_m_I': C_m_I, 'g_m_E': g_m_E, 'g_m_I': g_m_I,\n",
    "            'g_AMPA_ext_E': g_AMPA_ext_E, 'g_AMPA_rec_E': g_AMPA_rec_E, 'g_AMPA_ext_I': g_AMPA_ext_I,\n",
    "            'g_AMPA_rec_I': g_AMPA_rec_I, 'tau_AMPA': tau_AMPA,\n",
    "            'g_NMDA_E': g_NMDA_E, 'g_NMDA_I': g_NMDA_I,\n",
    "            'tau_NMDA_rise': tau_NMDA_rise, 'tau_NMDA_decay': tau_NMDA_decay,\n",
    "            'alpha': alpha, 'Mg2': Mg2,\n",
    "            'g_GABA_E': g_GABA_E, 'g_GABA_I': g_GABA_I, 'tau_GABA': tau_GABA,\n",
    "            'stimuli1': stimuli1, \n",
    "            #'stimuli2': stimuli2,\n",
    "            }\n",
    "\n",
    "objective_with_factor = partial(obj_func_utils.objective_function, net=net, namespace=namespace, current_monitor_E=current_monitor_E, r_E=r_E, r_I=r_I, r_E_sels=r_E_sels,\n",
    "                                 E_index_map=E_index_map, maximize=False)\n",
    "\n",
    "\n",
    "objective_func_tensor = partial(obj_func_utils.objective_function, net=net, namespace=namespace, current_monitor_E=current_monitor_E, r_E=r_E, r_I=r_I, r_E_sels=r_E_sels,\n",
    "                                 process_input_func=obj_func_utils.process_input_ibnn, process_output_func=obj_func_utils.process_output_ibnn, E_index_map=E_index_map,\n",
    "                                 maximize=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pls_stop \n",
    "# go to BP-IBNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test obj func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DC_start_time1 = 1000  # in ms\n",
    "DC_duration1 = 300  # in ms\n",
    "DC_amp1 = 0.1  # in nA\n",
    "DC_amp_slope1 = 0.001  # in nA/ms\n",
    "\n",
    "DC_start_time2 = 200  # in ms\n",
    "DC_duration2 = 1000  # in ms\n",
    "DC_amp2 = -0.05  # in nA\n",
    "DC_amp_slope2 = -0.001  # in nA/ms\n",
    "\n",
    "sino_start_time1 = 0  # in ms\n",
    "sino_duration1=1000  # in ms\n",
    "sino_amp1=0.5  # in nA\n",
    "sino_freq1=20  # in Hz\n",
    "\n",
    "sino_start_time2 = 1000  # in ms\n",
    "sino_duration2=500  # in ms\n",
    "sino_amp2=0.2  # in nA\n",
    "sino_freq2=10  # in Hz\n",
    "\n",
    "\n",
    "# make sure that we can run the below with no bugs\n",
    "params = [DC_start_time1, DC_duration1, DC_amp1, DC_amp_slope1,\n",
    "          DC_start_time2, DC_duration2, DC_amp2, DC_amp_slope2, \n",
    "        #   sino_start_time1, sino_duration1, sino_amp1, sino_freq1,\n",
    "        #   sino_start_time2, sino_duration2, sino_amp2, sino_freq2\n",
    "          ]\n",
    "\n",
    "objective_with_factor(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rerun (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#title_prefix = f'sino_amp2 = {sino_amp2} nA: '\n",
    "title_prefix = ''\n",
    "net.restore('initial')\n",
    "\n",
    "DC_input_ts = 1 * ms\n",
    "sino_input_ts = 0.1 * ms\n",
    "\n",
    "DC_start_time1 = 0  # in ms\n",
    "DC_duration1 = 1000  # in ms\n",
    "DC_amp1 = 0.1  # in nA\n",
    "DC_amp_slope1 = 0.001  # in nA/ms\n",
    "\n",
    "DC_start_time2 = 500  # in ms\n",
    "DC_duration2 = 2000  # in ms\n",
    "DC_amp2 = -0.05  # in nA\n",
    "DC_amp_slope2 = 0.001  # in nA/ms\n",
    "\n",
    "sino_start_time1 = 0  # in ms\n",
    "sino_duration1=3000  # in ms\n",
    "sino_amp1=0.08  # in nA\n",
    "sino_freq1=5  # in Hz\n",
    "\n",
    "sino_start_time2 = 1000  # in ms\n",
    "sino_duration2=2000  # in ms\n",
    "sino_amp2=0.06  # in nA\n",
    "sino_freq2=10  # in Hz\n",
    "\n",
    "\n",
    "DC_input1 = set_params_utils.set_DC_input(DC_amp=DC_amp1, # in nA\n",
    "            DC_duration=DC_duration1, # in ms\n",
    "            DC_start_time=DC_start_time1, # in ms\n",
    "            timestep=DC_input_ts\n",
    "            )\n",
    "\n",
    "DC_input2 = set_params_utils.set_DC_input(DC_amp=DC_amp2, # in nA\n",
    "            DC_duration=DC_duration2, # in ms\n",
    "            DC_start_time=DC_start_time2, # in ms\n",
    "            timestep=DC_input_ts\n",
    "            )\n",
    "\n",
    "sino_input1 = set_params_utils.set_sino_input(sino_start_time=sino_start_time1, # in ms\n",
    "                sino_duration=sino_duration1, # in ms\n",
    "                sino_amp=sino_amp1, # in nA\n",
    "                sino_freq=sino_freq1, # in Hz\n",
    "                timestep=sino_input_ts\n",
    "                )\n",
    "\n",
    "sino_input2 = set_params_utils.set_sino_input(sino_start_time=sino_start_time2, # in ms\n",
    "                sino_duration=sino_duration2, # in ms\n",
    "                sino_amp=sino_amp2, # in nA\n",
    "                sino_freq=sino_freq2, # in Hz\n",
    "                timestep=sino_input_ts\n",
    "                )\n",
    "\n",
    "\n",
    "\n",
    "net.run(5 * second, report='stdout')\n",
    "plotting_utils.plot_firing_rate(r_E, r_I, r_E_sels, title_prefix=title_prefix)\n",
    "# plotting_utils.plot_currents(current_monitor_E, current_monitor_I, currents_to_plot, E_index_map, title_prefix=title_prefix)\n",
    "\n",
    "plotting_utils.plot_currents(current_monitor_E, None, ['I_DC1', 'I_DC2'], E_index_map, title_prefix='')\n",
    "plt.gcf().subplots_adjust(left=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_in_window, rate_in_window, mean_fr = obj_func_utils.calculate_fr_in_window(r_E_sels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BO - IBNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://botorch.org/docs/tutorials/ibnn_bo/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infinite-Width Bayesian Neural Networks for Bayesian Optimization\n",
    "\n",
    "In this tutorial, we present an overview of infinite-width Bayesian neural networks (I-BNNs) [1, 2] and show how to use them as surrogate models for Bayesian optimization (BO).\n",
    "\n",
    "Consider an fully connected neural network with $L$ hidden layers, parameter weights drawn from $\\mathcal{N(0, \\sigma_w)}$, bias terms drawn from $\\mathcal{N(0, \\sigma_b)}$, and nonlinearity $\\phi$. In the infinite-width limit, the output of this network is exactly equivalent to $\\mathcal{GP}(\\mu, K^L)$. By the central limit theorem, we find $\\mu(x) = 0$, and we can also recursively define the covariance function as\n",
    "$$K^0(x, x')=\\sigma_b^2+\\sigma_w^2\\frac{x \\cdot x'}{d_\\text{input}}\\qquad K^l(x, x')=\\sigma_b^2+\\sigma_w^2F_\\phi(K^{l-1}(x, x'), K^{l-1}(x, x), K^{l-1}(x', x'))$$\n",
    "where $F_\\phi$ is a deterministic function based on the activation function $\\phi$.\n",
    "\n",
    "We will refer to this kernel as the \"I-BNN kernel\". Unlike many popular GP kernels, I-BNN covariance function is not based on Euclidean distance, allowing the GP to represent nonstationary functions. This is advantageous for many settings of Bayesian optimization, since the function we want to optimize may not have similar behavior throughout the entire input space. Furthermore, I-BNNs have been shown to work particularly well for BO problems with high-dimensional inputs [3].\n",
    "\n",
    "BoTorch has an implementation of I-BNNs with ReLU activations: `InfiniteWidthBNNKernel`.\n",
    "\n",
    "\n",
    "[1] [Y. Cho, and L. Saul. Kernel Methods for Deep Learning. Advances in Neural Information Processing Systems 22, 2009.](https://papers.nips.cc/paper_files/paper/2009/hash/5751ec3e9a4feab575962e78e006250d-Abstract.html)  \n",
    "[2] [J. Lee, Y. Bahri, R. Novak, S. Schoenholz, J. Pennington, and J. Dickstein. Deep Neural Networks as Gaussian Processes. International Conference on Learning Representations 2018.](https://arxiv.org/abs/1711.00165)  \n",
    "[3] [Y.L. Li, T.G.J. Rudner, A.G. Wilson. A Study of Bayesian Neural Network Surrogates for Bayesian Optimization. International Conference on Learning Representations 2024.](https://arxiv.org/abs/2305.20028)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype = torch.double\n",
    "tkwargs = {\"device\": device, \"dtype\": dtype}\n",
    "\n",
    "SMOKE_TEST = os.environ.get(\"SMOKE_TEST\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stim_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(sci_mode=False)\n",
    "dim = len(space)\n",
    "stim_bounds = torch.tensor([[dim.low, dim.high] for dim in space], dtype=torch.float).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = tensor([[DC_amp1, DC_start_time1, DC_duration1, DC_amp2, DC_start_time2, DC_duration2, \\\n",
    "#         sino_start_time1, sino_duration1, sino_amp1, sino_freq1, \\\n",
    "#         sino_start_time2, sino_duration2, sino_amp2, sino_freq2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initializing the Model**: We now define two versions of the I-BNN, constructed using a GP with an `InfiniteWidthBNNKernel`. One version has fixed user-specified values for $\\sigma^2_w$ and $\\sigma^2_b$, and the other uses the marginal log likelihood to optimize these hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get initial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acq_name = 'LogEI'\n",
    "train_x, train_y = ibnn_utils.generate_initial_data(objective_func_tensor, stim_bounds, n=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIMS = len(space)\n",
    "N_INIT = 2 if not SMOKE_TEST else 2\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype = torch.double\n",
    "tkwargs = {\"device\": device, \"dtype\": dtype}\n",
    "\n",
    "from functools import partial\n",
    "# define kernels\n",
    "ibnn_kernel = InfiniteWidthBNNKernel(2, device=device)\n",
    "ibnn_kernel.weight_var = 10.0\n",
    "ibnn_kernel.bias_var = 5.0\n",
    "ibnn_kernel = ScaleKernel(ibnn_kernel, device=device)\n",
    "\n",
    "# run BO loop\n",
    "acqf_classes = {\"LogEI\": LogExpectedImprovement}\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_x_stored = train_x\n",
    "init_y_stored = train_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_x = init_x_stored\n",
    "updated_y = init_y_stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize_hypers = True\n",
    "N_ITERATIONS = 500\n",
    "for acq_name, acqf_class in acqf_classes.items():\n",
    "    run_bo_with_acqf = partial(ibnn_utils.gp_bo_loop, f=objective_func_tensor, bounds=stim_bounds, acqf_class=acqf_class, \n",
    "                               init_x=updated_x, \n",
    "                               init_y=updated_y, \n",
    "                               n_iterations=N_ITERATIONS,\n",
    "                               )\n",
    "    ibnn_x, ibnn_y = run_bo_with_acqf(kernel=ibnn_kernel, optimize_hypers=optimize_hypers)\n",
    "    # matern_x, matern_y = run_bo_with_acqf(kernel=matern_kernel, optimize_hypers=True)\n",
    "    # rbf_x, rbf_y = run_bo_with_acqf(kernel=rbf_kernel, optimize_hypers=True)\n",
    "    results[acq_name] = {\n",
    "        \"BNN\": (ibnn_x, ibnn_y),\n",
    "        # \"Matern\": (matern_x, matern_y),\n",
    "        # \"RBF\": (rbf_x, rbf_y),\n",
    "    }\n",
    "\n",
    "    acq_name = 'LogEI'\n",
    "# updated_x = torch.cat([updated_x, results[acq_name]['BNN'][0]], dim=0)\n",
    "# updated_y = torch.cat([updated_y, results[acq_name]['BNN'][1]], dim=0)\n",
    "# # After your BO loop finishes\n",
    "# torch.save(updated_x, \"updated_x.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# updated_x = torch.cat([updated_x, results[acq_name]['BNN'][0]], dim=0)\n",
    "# updated_y = torch.cat([updated_y, results[acq_name]['BNN'][1]], dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BO with TuRBO-1 and TS/qEI\n",
    "\n",
    "In this tutorial, we show how to implement Trust Region Bayesian Optimization (TuRBO) [1] in a closed loop in BoTorch.\n",
    "\n",
    "This implementation uses one trust region (TuRBO-1) and supports either parallel expected improvement (qEI) or Thompson sampling (TS). We optimize the $20D$ Ackley function on the domain $[-5, 10]^{20}$ and show that TuRBO-1 outperforms qEI as well as Sobol.\n",
    "\n",
    "Since botorch assumes a maximization problem, we will attempt to maximize $-f(x)$ to achieve $\\max_x -f(x)=0$.\n",
    "\n",
    "[1]: [Eriksson, David, et al. Scalable global optimization via local Bayesian optimization. Advances in Neural Information Processing Systems. 2019](https://proceedings.neurips.cc/paper/2019/file/6c990b7aca7bc7058f5e98ea909e924b-Paper.pdf)\n",
    "\n",
    "Code is modified from:\n",
    "https://botorch.org/docs/tutorials/baxus/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype = torch.double\n",
    "SMOKE_TEST = os.environ.get(\"SMOKE_TEST\")\n",
    "\n",
    "torch.set_printoptions(sci_mode=False)\n",
    "dim = len(space)\n",
    "stim_bounds = torch.tensor([[dim.low, dim.high] for dim in space], dtype=torch.float).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define eval_objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def eval_objective(x):\n",
    "    \"\"\"This is a helper function we use to unnormalize and evalaute a point\"\"\"\n",
    "    return objective_func_tensor(unnormalize(x, stim_bounds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run loop\n",
    "This simple loop runs one instance of TuRBO-1 with Thompson sampling until convergence.\n",
    "\n",
    "TuRBO-1 is a local optimizer that can be used for a fixed evaluation budget in a multi-start fashion.  Once TuRBO converges, `state[\"restart_triggered\"]` will be set to true and the run should be aborted.  If you want to run more evaluations with TuRBO, you simply generate a new set of initial points and then keep generating batches until convergence or when the evaluation budget has been exceeded.  It's important to note that evaluations from previous instances are discarded when TuRBO restarts.\n",
    "\n",
    "NOTE: We use a `SingleTaskGP` with a noise constraint to keep the noise from getting too large as the problem is noise-free. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype = torch.double\n",
    "SMOKE_TEST = os.environ.get(\"SMOKE_TEST\")\n",
    "\n",
    "n_init = 2\n",
    "\n",
    "X_turbo = turbo_utils.get_initial_points(dim, n_init, dtype=dtype, device=device)\n",
    "Y_turbo = torch.tensor(\n",
    "    [eval_objective(x) for x in X_turbo], dtype=dtype, device=device\n",
    ").unsqueeze(-1)\n",
    "\n",
    "init_x_stored = X_turbo\n",
    "init_y_stored = Y_turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "dtype = torch.double\n",
    "SMOKE_TEST = os.environ.get(\"SMOKE_TEST\")\n",
    "\n",
    "batch_size = 1\n",
    "max_iter= 500\n",
    "max_cholesky_size = float(\"inf\")  # Always use Cholesky\n",
    "\n",
    "state = turbo_utils.TurboState(dim=dim, batch_size=batch_size)\n",
    "\n",
    "NUM_RESTARTS = 10 if not SMOKE_TEST else 2\n",
    "RAW_SAMPLES = 512 if not SMOKE_TEST else 4\n",
    "N_CANDIDATES = min(5000, max(2000, 200 * dim)) if not SMOKE_TEST else 4\n",
    "\n",
    "\n",
    "X_turbo, Y_turbo = turbo_utils.run_turbo_loop(X_turbo, Y_turbo, eval_objective, dim,\n",
    "                   max_iter=max_iter, batch_size=batch_size,\n",
    "                   max_cholesky_size=max_cholesky_size, device=device, dtype=dtype,\n",
    "                   SMOKE_TEST=SMOKE_TEST,\n",
    "                   result_dir='all_stored_results/turbo_results'\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## baseline BO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: a basic version of BO is used here, but for the purpose of the final projects, we need to make changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_calls = 500\n",
    "objective_with_factor = partial(obj_func_utils.objective_function, net=net, namespace=namespace, current_monitor_E=current_monitor_E, r_E=r_E, r_I=r_I, r_E_sels=r_E_sels,\n",
    "                                 E_index_map=E_index_map, maximize=False)\n",
    "\n",
    "res = gp_minimize(objective_with_factor, # the function to minimize\n",
    "                  space,\n",
    "                  n_initial_points= 2,\n",
    "                  acq_func=\"EI\",      # the acquisition function\n",
    "                  n_calls=n_calls,         # the number of evaluations of f\n",
    "                  n_random_starts=5,  # the number of random initialization points\n",
    "                  noise='gaussian',       # the noise level (optional)\n",
    "                  random_state=1234)   # the random seed\n",
    "\n",
    "\n",
    "train_x, train_y = baseline_bo_utils.save_bo_results(res, result_dir='all_stored_results/bo_results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = baseline_bo_utils.save_bo_results(res, result_dir='all_stored_results/bo_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pls_stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show best results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IBNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_recent_folder = shared_utils.get_most_recent_result_subfolder_name(result_dir='all_stored_results/ibnn_results/optimize_hypers', prefix = 'run_')\n",
    "updated_x = torch.load(os.path.join(most_recent_folder, \"updated_x.pt\"))\n",
    "updated_y = torch.load(os.path.join(most_recent_folder, \"updated_y.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_utils.plot_best_results(updated_x, updated_y, objective_func_tensor, num_top_points=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_recent_folder = shared_utils.get_most_recent_result_subfolder_name(result_dir='all_stored_results/turbo_results', prefix = 'run_')\n",
    "# most_recent_folder = 'all_stored_results/turbo_results/temp_results'\n",
    "X_turbo = torch.load(os.path.join(most_recent_folder, \"updated_x.pt\"))\n",
    "updated_x = unnormalize(X_turbo, stim_bounds)\n",
    "Y_turbo = torch.load(os.path.join(most_recent_folder, \"updated_y.pt\"))\n",
    "updated_y = Y_turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_utils.plot_best_results(updated_x, updated_y, objective_func_tensor, num_top_points=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## baseline BO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_recent_folder = shared_utils.get_most_recent_result_subfolder_name(result_dir='all_stored_results/bo_results', prefix = 'run_')\n",
    "# most_recent_folder = 'all_stored_results/turbo_results/temp_results'\n",
    "updated_x = torch.load(os.path.join(most_recent_folder, \"updated_x.pt\"))\n",
    "updated_y = torch.load(os.path.join(most_recent_folder, \"updated_y.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_utils.plot_best_results(updated_x, updated_y, objective_func_tensor, num_top_points=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare all three"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot top param spread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_top_points = 20\n",
    "\n",
    "results_dir_dict = {'baseline': 'all_stored_results/bo_results',\n",
    "                    'turbo': 'all_stored_results/turbo_results',\n",
    "                    'ibnn': 'all_stored_results/ibnn_results/optimize_hypers'}\n",
    "\n",
    "x_dict, y_dict = shared_utils.load_top_optimization_results(results_dir_dict, stim_bounds, prefix='run_')\n",
    "\n",
    "# indices_to_plot = [2, 3, 6, 7]\n",
    "indices_to_plot = range(8)\n",
    "shared_utils.plot_top_param_distributions(space, x_dict, y_dict, num_top_points=20, indices_to_plot=indices_to_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot iter vs value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not cummax\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "for method, x_vals in x_dict.items():\n",
    "    y_vals = y_dict[method]\n",
    "    ax.plot(range(len(y_vals)), y_vals, label=method, alpha=0.5, linewidth=1)\n",
    "ax.set_xlabel(\"BO Iterations\")\n",
    "ax.set_ylabel(\"Objective Value\")\n",
    "ax.legend()\n",
    "plt.title(\"Objective Value Over Iterations\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cummax\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "for method, x_vals in x_dict.items():\n",
    "    y_vals = y_dict[method]\n",
    "    cum_max = (torch.cummax(y_vals, dim=0)[0]).cpu()\n",
    "    ax.plot(range(len(cum_max)), cum_max, label=method, alpha=0.5, linewidth=1)\n",
    "ax.set_xlabel(\"BO Iterations\")\n",
    "ax.set_ylabel(\"Max Value\")\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "brian2_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
